<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../css/style.post.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet">
    <title>About Jack Miller</title>
</head>
<!-- meta, summary, bibtex -->

<body>
    <header id="banner">
        <h2><a href="../index.html">Jack Miller</a></h2>
        <nav>
            <ul>
                <li>
                    <a href="../contact.html" title="contact">contact</a>
                </li>
            </ul>
        </nav>
    </header>
    <main id="content">
        <h2>Measuring Sharpness in Grokking</h2>
        <p><i>Paper accepted at Bridging the Gap Between Practice and Theory in Deep Learning (ICLR2024).
                See <a href="https://arxiv.org/abs/2402.08946v1" target="_blank">here</a>.</i></p>
        <!-- Line break not so large though-->
        <div id="summary">
            <p>Neural networks sometimes exhibit grokking, a phenomenon where perfect or near-perfect performance is
                achieved on a validation set well after the same performance has been obtained on the corresponding
                training set. In this workshop paper, we introduce a robust technique for measuring grokking, based on
                fitting an appropriate functional form. We then use this to investigate the sharpness of transitions in
                training and validation accuracy under two settings. The first setting is the theoretical framework
                developed by <a href="https://arxiv.org/abs/2310.16441" target="_blank">Levi et al. (2023)</a> where
                closed form
                expressions are readily accessible. The second setting
                is a two-layer MLP trained to predict the parity of bits, with grokking induced by the concealment
                strategy we developed in our paper <a href="grokking_beyond_neural_networks.html"
                    target="_blank">Grokking Beyond Neural Networks</a>. We find that trends between
                relative grokking gap and grokking
                sharpness are similar in both settings when using absolute and relative measures of sharpness.
                Reflecting on this, we make progress toward explaining some trends and identify the need for further
                study to untangle the various mechanisms which influence the sharpness of grokking.
            </p>
        </div>
        <!-- <h3>Links</h3>
        <div id="links">
            <ul>
                <li><a href="https://openreview.net/forum?id=X5ijJFkEpr" target="_blank">OpenReview page</a>
                </li>
            </ul>
        </div> -->
    </main>
    <footer id="footer">
        <!-- Fix copyright... no longer grey... -->
        <center>Copyright Â© 2024 Jack Miller</center>
    </footer>
</body>

</html>