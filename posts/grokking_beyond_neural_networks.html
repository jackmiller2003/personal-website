<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../css/style.post.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet">
    <title>About Jack Miller</title>
</head>
<!-- meta, summary, bibtex -->

<body>
    <header id="banner">
        <h2><a href="../index.html">Jack Miller</a></h2>
        <nav>
            <ul>
                <li>
                    <a href="../contact.html" title="contact">contact</a>
                </li>
            </ul>
        </nav>
    </header>
    <main id="content">
        <h2>Grokking Beyond Neural Networks</h2>
        <p><i>Paper accepted in Transactions on Machine Learning Research. See <a
                    href="https://openreview.net/forum?id=ux9BrxPCl8" target="_blank">here</a>.</i></p>
        <!-- Line break not so large though-->
        <div id="summary">
            <p>In some settings neural networks exhibit a phenomenon known as <i>grokking</i>, where they achieve
                perfect or near-perfect accuracy on the validation set long after the same performance has been achieved
                on
                the training set. In work on grokking with Thang Bui and Charles O'Neill, we discovered that grokking
                is
                not limited to neural networks but occurs in other settings such as Gaussian process (GP)
                classification, GP
                regression, linear regression and Bayesian neural networks. We also uncovered a mechanism by which to
                induce
                grokking on algorithmic datasets via the addition of dimensions containing spurious information. The
                presence of the phenomenon in non-neural architectures shows that grokking is not restricted to settings
                considered in current theoretical and empirical studies. Instead, grokking may be possible in any model
                where solution search is guided by complexity and error.
            </p>
        </div>
        <h3>Links</h3>
        <div id="links">
            <ul>
                <li><a href="https://www.youtube.com/watch?v=5XSQhZsYQoU&t=1s" target="_blank">Video walkthrough</a>
                </li>
                <li><a href="https://www.lesswrong.com/posts/YXeScZmfCGiX4fQGt/grokking-beyond-neural-networks"
                        target="_blank">Summary article on LessWrong </a></li>
            </ul>
        </div>
    </main>
    <footer id="footer">
        <!-- Fix copyright... no longer grey... -->
        <center>Copyright Â© 2024 Jack Miller</center>
    </footer>
</body>

</html>